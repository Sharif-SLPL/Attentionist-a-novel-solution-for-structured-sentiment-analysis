{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselines.ipynb",
      "provenance": [],
      "mount_file_id": "121gdm01vBeyn-ENfxZ57G4LGl-7HQQkP",
      "authorship_tag": "ABX9TyNYCYf/ov0jmoa9MSHDs4fL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadra-barikbin/novel-solutions-for-sentiment-analysis/blob/main/baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml==4.3.2 tqdm==4.56.0 torch==1.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mupQK6TPHg-",
        "outputId": "37fd241f-88a6-420d-9ce0-11efb9e0440f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml==4.3.2 in /usr/local/lib/python3.7/dist-packages (4.3.2)\n",
            "Requirement already satisfied: tqdm==4.56.0 in /usr/local/lib/python3.7/dist-packages (4.56.0)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.3.1) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install matplotlib==3.1.2 gensim==3.8.1 stanza==1.1.1 nltk==3.4.5 torchtext==0.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngfCAqtVr2gR",
        "outputId": "61ecab8d-7c7b-4177-c744-04d0ebc52de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.1.2 in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: stanza==1.1.1 in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (3.4.5)\n",
            "Requirement already satisfied: torchtext==0.3.1 in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2) (3.0.8)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (6.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza==1.1.1) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza==1.1.1) (3.17.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza==1.1.1) (4.56.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.2) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.1.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.1.1) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('en')\n",
        "stanza.download('es')\n",
        "stanza.download('eu')\n",
        "stanza.download('ca')\n",
        "stanza.download('nb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACKFMSZmQieX",
        "outputId": "3540459c-0f32-41ea-e771-7b1dea395b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 28.0MB/s]                    \n",
            "2022-04-30 12:29:50 INFO: Downloading default packages for language: en (English)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/en/default.zip: 100%|██████████| 428M/428M [01:18<00:00, 5.43MB/s]\n",
            "2022-04-30 12:31:16 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 62.1MB/s]                    \n",
            "2022-04-30 12:31:16 INFO: Downloading default packages for language: es (Spanish)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/es/default.zip: 100%|██████████| 583M/583M [01:46<00:00, 5.46MB/s]\n",
            "2022-04-30 12:33:12 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 38.7MB/s]                    \n",
            "2022-04-30 12:33:12 INFO: Downloading default packages for language: eu (Basque)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/eu/default.zip: 100%|██████████| 220M/220M [00:39<00:00, 5.64MB/s]\n",
            "2022-04-30 12:33:56 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 41.6MB/s]                    \n",
            "2022-04-30 12:33:56 INFO: Downloading default packages for language: ca (Catalan)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/ca/default.zip: 100%|██████████| 227M/227M [00:39<00:00, 5.69MB/s]\n",
            "2022-04-30 12:34:41 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 44.0MB/s]                    \n",
            "2022-04-30 12:34:41 INFO: Downloading default packages for language: nb (Norwegian_Bokmaal)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/nb/default.zip: 100%|██████████| 225M/225M [01:59<00:00, 1.88MB/s]\n",
            "2022-04-30 12:36:45 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our baselines are the ones introduced in the task github repo. First one takes a dependency graph parsing approach and is originally based on [(Barnes et al. 2021)](https://arxiv.org/abs/2105.14504). Second is a simple sequence labelling LSTM."
      ],
      "metadata": {
        "id": "Lj_nBRIPJTiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/sadra-barikbin/semeval22_structured_sentiment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP4tVFdkKmH4",
        "outputId": "27960996-e17e-4476-905d-6242d465b5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semeval22_structured_sentiment'...\n",
            "remote: Enumerating objects: 993, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 993 (delta 59), reused 69 (delta 45), pack-reused 894\u001b[K\n",
            "Receiving objects: 100% (993/993), 16.08 MiB | 24.47 MiB/s, done.\n",
            "Resolving deltas: 100% (488/488), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd semeval22_structured_sentiment/data/mpqa && bash process_mpqa.sh\n",
        "! cd semeval22_structured_sentiment/data/darmstadt_unis && bash process_darmstadt.sh"
      ],
      "metadata": {
        "id": "O-PKXw8kO9TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/baselines/graph_parser\n",
        "if [ -d embeddings ]; then\n",
        "    echo \"Using downloaded word embeddings\"\n",
        "else\n",
        "    mkdir embeddings\n",
        "    cd embeddings\n",
        "    wget http://vectors.nlpl.eu/repository/20/58.zip\n",
        "    wget http://vectors.nlpl.eu/repository/20/32.zip\n",
        "    wget http://vectors.nlpl.eu/repository/20/34.zip\n",
        "    wget http://vectors.nlpl.eu/repository/20/18.zip\n",
        "    wget http://vectors.nlpl.eu/repository/20/68.zip\n",
        "cd ..\n",
        "fi"
      ],
      "metadata": {
        "id": "oRNwSjD8ZnDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c4b1fd-8c6c-47b1-92a0-cf180ee050e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline 1 - Dependency Graph Parsing"
      ],
      "metadata": {
        "id": "cya9BpjpKeTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cd semeval22_structured_sentiment/baselines/graph_parser && bash get_baseline.sh"
      ],
      "metadata": {
        "id": "spnZNM2SKdlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c73c057-9bb9-41aa-dd78-8645a69e6c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-30 12:38:32 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "| depparse  | ewt     |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:38:32 INFO: Use device: gpu\n",
            "2022-04-30 12:38:32 INFO: Loading: tokenize\n",
            "2022-04-30 12:38:32 INFO: Loading: pos\n",
            "2022-04-30 12:38:35 INFO: Loading: lemma\n",
            "2022-04-30 12:38:35 INFO: Loading: depparse\n",
            "2022-04-30 12:38:36 INFO: Done loading processors!\n",
            "Dataset: ../../data/darmstadt_unis\n",
            "Setup: head_final\n",
            "2022-04-30 12:40:08 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "| depparse  | ewt     |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:40:08 INFO: Use device: gpu\n",
            "2022-04-30 12:40:08 INFO: Loading: tokenize\n",
            "2022-04-30 12:40:08 INFO: Loading: pos\n",
            "2022-04-30 12:40:11 INFO: Loading: lemma\n",
            "2022-04-30 12:40:11 INFO: Loading: depparse\n",
            "2022-04-30 12:40:12 INFO: Done loading processors!\n",
            "Dataset: ../../data/mpqa\n",
            "Setup: head_final\n",
            "2022-04-30 12:45:52 INFO: Loading these models for language: ca (Catalan):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:45:52 INFO: Use device: gpu\n",
            "2022-04-30 12:45:52 INFO: Loading: tokenize\n",
            "2022-04-30 12:45:52 INFO: Loading: pos\n",
            "2022-04-30 12:45:55 INFO: Loading: lemma\n",
            "2022-04-30 12:45:55 INFO: Loading: depparse\n",
            "2022-04-30 12:45:56 INFO: Done loading processors!\n",
            "Dataset: ../../data/multibooked_ca\n",
            "Setup: head_final\n",
            "2022-04-30 12:46:55 INFO: Loading these models for language: eu (Basque):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bdt     |\n",
            "| pos       | bdt     |\n",
            "| lemma     | bdt     |\n",
            "| depparse  | bdt     |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:46:55 INFO: Use device: gpu\n",
            "2022-04-30 12:46:55 INFO: Loading: tokenize\n",
            "2022-04-30 12:46:55 INFO: Loading: pos\n",
            "2022-04-30 12:46:57 INFO: Loading: lemma\n",
            "2022-04-30 12:46:57 INFO: Loading: depparse\n",
            "2022-04-30 12:46:59 INFO: Done loading processors!\n",
            "Dataset: ../../data/multibooked_eu\n",
            "Setup: head_final\n",
            "2022-04-30 12:47:55 INFO: \"no\" is an alias for \"nb\"\n",
            "2022-04-30 12:47:55 INFO: Loading these models for language: nb (Norwegian_Bokmaal):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bokmaal |\n",
            "| pos       | bokmaal |\n",
            "| lemma     | bokmaal |\n",
            "| depparse  | bokmaal |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:47:55 INFO: Use device: gpu\n",
            "2022-04-30 12:47:55 INFO: Loading: tokenize\n",
            "2022-04-30 12:47:55 INFO: Loading: pos\n",
            "2022-04-30 12:47:58 INFO: Loading: lemma\n",
            "2022-04-30 12:47:58 INFO: Loading: depparse\n",
            "2022-04-30 12:47:59 INFO: Done loading processors!\n",
            "Dataset: ../../data/norec\n",
            "Setup: head_final\n",
            "2022-04-30 12:54:11 INFO: Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:54:11 INFO: Use device: gpu\n",
            "2022-04-30 12:54:11 INFO: Loading: tokenize\n",
            "2022-04-30 12:54:11 INFO: Loading: pos\n",
            "2022-04-30 12:54:13 INFO: Loading: lemma\n",
            "2022-04-30 12:54:13 INFO: Loading: depparse\n",
            "2022-04-30 12:54:15 INFO: Done loading processors!\n",
            "Dataset: ../../data/opener_es\n",
            "Setup: head_final\n",
            "2022-04-30 12:55:27 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "| depparse  | ewt     |\n",
            "=======================\n",
            "\n",
            "2022-04-30 12:55:27 INFO: Use device: gpu\n",
            "2022-04-30 12:55:27 INFO: Loading: tokenize\n",
            "2022-04-30 12:55:27 INFO: Loading: pos\n",
            "2022-04-30 12:55:30 INFO: Loading: lemma\n",
            "2022-04-30 12:55:30 INFO: Loading: depparse\n",
            "2022-04-30 12:55:31 INFO: Done loading processors!\n",
            "Dataset: ../../data/opener_en\n",
            "Setup: head_final\n",
            "--2022-04-30 12:56:44--  http://vectors.nlpl.eu/repository/20/58.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 895180440 (854M) [application/zip]\n",
            "Saving to: ‘58.zip’\n",
            "\n",
            "58.zip              100%[===================>] 853.71M   103MB/s    in 8.4s    \n",
            "\n",
            "2022-04-30 12:56:53 (101 MB/s) - ‘58.zip’ saved [895180440/895180440]\n",
            "\n",
            "--2022-04-30 12:56:53--  http://vectors.nlpl.eu/repository/20/32.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 321933114 (307M) [application/zip]\n",
            "Saving to: ‘32.zip’\n",
            "\n",
            "32.zip              100%[===================>] 307.02M  97.5MB/s    in 3.1s    \n",
            "\n",
            "2022-04-30 12:56:56 (97.5 MB/s) - ‘32.zip’ saved [321933114/321933114]\n",
            "\n",
            "--2022-04-30 12:56:56--  http://vectors.nlpl.eu/repository/20/34.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 602902722 (575M) [application/zip]\n",
            "Saving to: ‘34.zip’\n",
            "\n",
            "34.zip              100%[===================>] 574.97M   104MB/s    in 5.6s    \n",
            "\n",
            "2022-04-30 12:57:02 (102 MB/s) - ‘34.zip’ saved [602902722/602902722]\n",
            "\n",
            "--2022-04-30 12:57:02--  http://vectors.nlpl.eu/repository/20/18.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 610800283 (583M) [application/zip]\n",
            "Saving to: ‘18.zip’\n",
            "\n",
            "18.zip              100%[===================>] 582.50M   102MB/s    in 5.8s    \n",
            "\n",
            "2022-04-30 12:57:08 (100 MB/s) - ‘18.zip’ saved [610800283/610800283]\n",
            "\n",
            "--2022-04-30 12:57:08--  http://vectors.nlpl.eu/repository/20/68.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2002844899 (1.9G) [application/zip]\n",
            "Saving to: ‘68.zip’\n",
            "\n",
            "68.zip              100%[===================>]   1.87G   102MB/s    in 19s     \n",
            "\n",
            "2022-04-30 12:57:27 (100 MB/s) - ‘68.zip’ saved [2002844899/2002844899]\n",
            "\n",
            "Running darmstadt_unis - head_final\n",
            "mkdir: cannot create directory ‘experiments/darmstadt_unis/head_final’: File exists\n",
            "Running mpqa - head_final\n",
            "mkdir: cannot create directory ‘experiments/mpqa/head_final’: File exists\n",
            "Running multibooked_ca - head_final\n",
            "mkdir: cannot create directory ‘experiments/multibooked_ca/head_final’: File exists\n",
            "Running multibooked_eu - head_final\n",
            "mkdir: cannot create directory ‘experiments/multibooked_eu/head_final’: File exists\n",
            "Running norec - head_final\n",
            "mkdir: cannot create directory ‘experiments/norec/head_final’: File exists\n",
            "Running opener_es - head_final\n",
            "mkdir: cannot create directory ‘experiments/opener_es/head_final’: File exists\n",
            "Running opener_en - head_final\n",
            "mkdir: cannot create directory ‘experiments/opener_en/head_final’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/baselines/graph_parser/\n",
        "for DATASET in darmstadt_unis mpqa multibooked_ca multibooked_eu norec opener_es opener_en; do\n",
        "    python3 convert_to_conllu.py --json_dir ../../data/\"$DATASET\" --out_dir sentiment_graphs/\"$DATASET\" --setup head_final\n",
        "done;"
      ],
      "metadata": {
        "id": "aWQVj2xHwOYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/baselines/graph_parser\n",
        "for ds in opener_en opener_es darmstadt_unis multibooked_ca multibooked_eu; do\n",
        "  if [ $ds == norec ]; then\n",
        "      embed=embeddings/58.zip\n",
        "  elif [ $ds == multibooked_eu ]; then\n",
        "      embed=embeddings/32.zip\n",
        "  elif [ $ds == multibooked_ca ]; then\n",
        "      embed=embeddings/34.zip\n",
        "  elif [ $ds == mpqa ]; then\n",
        "      embed=embeddings/18.zip\n",
        "  elif [ $ds == darmstadt_unis ]; then\n",
        "      embed=embeddings/18.zip\n",
        "  elif [ $ds == opener_en ]; then\n",
        "      embed=embeddings/18.zip\n",
        "  elif [ $ds == opener_es ]; then\n",
        "      embed=embeddings/68.zip\n",
        "  else\n",
        "      echo \"NO EMBEDDINGS SUPPLIED FOR THIS DATASET\"\n",
        "      exit\n",
        "  fi\n",
        "  bash ./inference.sh sentiment_graphs/$ds/head_final/test.conllu experiments/$ds/head_final $embed\n",
        "done;"
      ],
      "metadata": {
        "id": "InQZY4wKrMzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/evaluation\n",
        "for ds in mpqa norec; do\n",
        "  echo $ds:$(python3 evaluate_single_dataset.py ../data/$ds/test.json ../baselines/graph_parser/experiments/$ds/head_final/test.conllu.json)\n",
        "done;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kql8vbeIIUY5",
        "outputId": "2ed989f7-2be4-4b18-f5f4-cb27d4640b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpqa:Sentiment Tuple F1: 0.159\n",
            "norec:Sentiment Tuple F1: 0.282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/evaluation\n",
        "for ds in opener_en opener_es darmstadt_unis multibooked_ca multibooked_eu; do\n",
        "  echo $ds:$(python3 evaluate_single_dataset.py ../data/$ds/test.json ../baselines/graph_parser/experiments/$ds/head_final/test.conllu.json)\n",
        "done;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmyZzVeklqHB",
        "outputId": "580257a7-e626-4b89-8d68-40d066b94e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opener_en:Sentiment Tuple F1: 0.525\n",
            "opener_es:Sentiment Tuple F1: 0.502\n",
            "darmstadt_unis:Sentiment Tuple F1: 0.211\n",
            "multibooked_ca:Sentiment Tuple F1: 0.545\n",
            "multibooked_eu:Sentiment Tuple F1: 0.573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline 2 - Sequence Labelling\n",
        "\n",
        "This model extracts both expressions and relations using LSTM. Node Extractor in our work is inspired of this model's expression extractor."
      ],
      "metadata": {
        "id": "isnnAtYES9Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cd semeval22_structured_sentiment/baselines/sequence_labeling && bash get_baselines.sh"
      ],
      "metadata": {
        "id": "gSrz4tcMUJX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/baselines/sequence_labeling\n",
        "EMBEDDINGDIR=\"../graph_parser/embeddings\"\n",
        "for DATASET in darmstadt_unis mpqa multibooked_ca multibooked_eu norec opener_es opener_en; do\n",
        "  python3 inference.py -data \"$DATASET\" -file test.json -device cuda\n",
        "done;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t22i2U_NS3H",
        "outputId": "1bf2c41b-8228-4ebb-eb63-7a3b6835c38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(BATCH_SIZE=50, DATADIR='darmstadt_unis', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='mpqa', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='multibooked_ca', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='multibooked_eu', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='norec', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='opener_es', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n",
            "Namespace(BATCH_SIZE=50, DATADIR='opener_en', DEVICE='cuda', FILE='test.json')\n",
            "opening sources model...\n",
            "opening targets model...\n",
            "opening expressions model...\n",
            "loading best relation prediction model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tcmalloc: large alloc 2125438976 bytes == 0x14942000 @  0x7fc1b80b7001 0x7fc1b55411af 0x7fc1b5597c23 0x7fc1b5598a87 0x7fc1b563a823 0x5936cc 0x548c51 0x51566f 0x593dd7 0x5118f8 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fc1b7cb2c87 0x5b621a\n",
            "tcmalloc: large alloc 2125438976 bytes == 0x15d7e0000 @  0x7fc1b80b7001 0x7fc1b55411af 0x7fc1b5597c23 0x7fc1b5598a87 0x7fc1b563a823 0x5936cc 0x548c51 0x51566f 0x593dd7 0x5118f8 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fc1b7cb2c87 0x5b621a\n",
            "tcmalloc: large alloc 2125438976 bytes == 0x14942000 @  0x7fc1b80b7001 0x7fc1b55411af 0x7fc1b5597c23 0x7fc1b5598a87 0x7fc1b563a823 0x5936cc 0x548c51 0x51566f 0x593dd7 0x5118f8 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fc1b7cb2c87 0x5b621a\n",
            "tcmalloc: large alloc 2124947456 bytes == 0x15d7e0000 @  0x7fc1b80b7001 0x7fc1b55411af 0x7fc1b5597c23 0x7fc1b5598a87 0x7fc1b563a823 0x5936cc 0x548c51 0x51566f 0x593dd7 0x5118f8 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fc1b7cb2c87 0x5b621a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd semeval22_structured_sentiment/evaluation\n",
        "for ds in opener_en opener_es darmstadt_unis multibooked_ca multibooked_eu mpqa norec; do\n",
        "  echo $ds:$(python3 evaluate_single_dataset.py ../data/$ds/test.json ../baselines/sequence_labeling/saved_models/relation_prediction/$ds/prediction.json)\n",
        "done;"
      ],
      "metadata": {
        "id": "kZ63ycPaTVoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8adf248-31c1-49c3-b4f5-24da0feca23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opener_en:Sentiment Tuple F1: 0.315\n",
            "opener_es:Sentiment Tuple F1: 0.265\n",
            "darmstadt_unis:Sentiment Tuple F1: 0.130\n",
            "multibooked_ca:Sentiment Tuple F1: 0.337\n",
            "multibooked_eu:Sentiment Tuple F1: 0.348\n",
            "mpqa:Sentiment Tuple F1: 0.024\n",
            "norec:Sentiment Tuple F1: 0.192\n"
          ]
        }
      ]
    }
  ]
}